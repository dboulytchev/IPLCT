\chapter{Straight Line Programs}

In this chapter we introduce the language of \emph{straight line} programs which can be considered as a smallest
non-trivial subset of \lama. In this subset all programs are executed sequentially statement by statement with
no branching. Thus, any program either comes to an end or stops due to an error, but cannot loop forever. We
use this simple language to showcase all the ingredients of our approach to language description: abstract and
concrete syntax specification, denotational and operational semantics, etc. We also introduce some components of
the compiler we will be working on: source-level interpreter, stack machine compiler and interpreter, and
\texttt{x86} code generator.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.7]{images/02-01.eps}
  \caption{Abstract Syntax for Expressions}
  \label{expression-syntax}
\end{figure}

\section{Expressions}


Syntactically, our language encorporates two \emph{syntactic categories}: expressions and statements. We start from describing
so-called \emph{abstract syntax} for the expression category. We consider a countable set of \emph{variables}

\[
\mathscr{X}=\{x_1,\,x_2,\,\dots\}
\]

and a set of \emph{binary operators}

\[
\otimes= \{+,\, -,\, \times,\, /,\, \%,\, <,\, \le,\, >,\, \ge,\, =,\,\ne,\, \vee,\, \wedge\}
\]

which contains all thirteen built-in \lama operators. Then, the category of expressions $\mathscr{E}$ can be defined by
the following recursive scheme:

\[
\begin{array}{rcl}
  \mathscr{E} & = & \mathscr{X} \\
              &   & \mathbb{N} \\
              &   & \mathscr{E}\otimes\mathscr{E}
\end{array}
\]

This scheme defines a countable set of \emph{labeled ordered trees} of finite height: each node of such a tree is labeled, and for any node the order
of its immediate subtrees is essential. The simplest trees of this form are just leaves labeled with either variables or natural numbers; we simply
write $\mathscr{X}$ or $\mathbb{N}$ in the first two lines of definition of $\mathscr{E}$, but actually we mean tree nodes \emph{labeled} by the symbols of
these sets. As for the third line, it stipulates that for arbitrary two expressions $e_1,\,e_2\in\mathscr{E}$ a tree with a root labeled with any symbol
from $\otimes$ and immediate subtress $e_1$ and $e_2$ is also expression (see Fig.~\ref{expression-syntax}).

We call this definition \emph{abstract} syntax because it describes nothing more than a subordination between elementary constructs. In order to represent
expressions in some medium, however, we need \emph{concrete} syntax; it is easy to anticipate that there can be multiple concrete syntaxes for given
abstract one. In Fig.~\ref{expression-concrete} we give some examples of those for expressions: the first (\emph{a}) consists of graphical elements such as
circles, lines, texts, etc. Another one (\emph{b}) is the familiar \emph{infix notation} which includes numbers, letters, binary
operators and brackets. Yet another (but by no means the last one) is \emph{reverse Polish notation} (\emph{c}), in which binary operators are
put \emph{after} the operands they connect. In what follows we will stick with infix notation.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.7]{images/02-02.eps}
  \caption{Various Concrete Syntaxes for Expression Language}
  \label{expression-concrete}
\end{figure}

Now we need to define the semantic domain for the semantics of expressions. We already hinted that this domain should be shaped like a set of some
data processing functions $\mathfrak{D}\to\mathfrak{D}$; however, we need to be more specific.

As we deal with arithmetic expressions it is rather natural to expect that the results of their evaluation are interger values, i.e. $\mathbb{Z}$ (as we agreed
earlier, we assume $\mathbb{Z}\subset\mathfrak{D}$); on the other hand, the value of an expression depends on the values of variables it contains. We can
encode these values as a \emph{state}~--- a function which maps variables to integer values:

\[
St : \mathscr{X} \to \mathbb{Z}
\]

There is nothing wrong with assuming $St\subset\mathfrak{D}$: as any expression can contain only a finite number of variables we are interested only in
states with finite domains which can be encoded, for example, as finite lists of pairs. Thus, finally, we have the following ``type'' for the semantics
of expressions:

\[
\sembr{\bullet}^\ph_\mathscr{E}:\mathscr{E}\to(St\to\mathbb{Z})
\]

\subsection{Denotational Semantics}

There are multiple ways to give the semantics for a language formally. Here we use so-called \emph{denotational} way in which it is immediately
specified what object from the semantic domain corresponds to a given language construct. For this concrete language denotational semantics
looks simple and natural; however, for more advanced languages more advanced mathematical apparatus would be required. It is also worth mentioning that,
as a rule, denotational semantics gives us a very abstract, high-level view on the behavior of programs, which may or may not be desirable from a
practical standpoint.


\begin{figure}[t]
\[
\begin{array}{rcl}
  \sembr{z}^\ph_\mathscr{E} & = & \sigma \mapsto z \\  
  \sembr{x}^\ph_\mathscr{E} & = & \sigma \mapsto \sigma\,x \\
  \sembr{e_1\otimes e_2}^\ph_\mathscr{E} & = & \sigma \mapsto \sembr{e_2}^\ph_\mathscr{E}\,\sigma\oplus\sembr{e_2}^\ph_\mathscr{E}\,\sigma
\end{array}
\]
\caption{Denotational Semantics of Expressions}
\label{se-denot}
\end{figure}


The denotational semantics for expressions is shown in Fig.~\ref{se-denot}.
We give here three equations, one for each syntactic form. In the right-hand side of each equation we immediately
give the object (a function from states to integers) which corresponds to the semantics of the expression in the
left-hand side. The notation $\star \mapsto \bullet$ is used to denote a function from $\star$ to $\bullet$; we refrain from
using the lambda notation since these functions are elements of the \emph{meta-language} (the language we use to describe the
semantics), not of the \emph{object} one (the language which semantics is being described).

In the first equation, when the expression is a natural number $z$, its semantics is a constant function, which for
any state $\sigma$ return just this number $z$.

When the expression in question is a variable $x$, its semantics is a function which, given a state $\sigma$, returns
the value this state assigns to this variable.

Finally, when the expression is a binary operator with two subexpressions $e_1$ and $e_2$, its semantics is a function which, given a state $\sigma$,
first calcalates the values of subexpressions $e_1$ and $e_2$ in the same state, and then combines them using a certain arithmetic operator $\oplus$.
The correspondence between $\otimes$ and $\oplus$ is described by the following table:

\begin{center}
\begin{tabular}{c|cl}
  $\otimes$     & $\oplus$ in \lama\\
  \hline
  $+$      & \lstinline|+|   \\
  $-$      & \lstinline|-|   \\
  $\times$ & \lstinline|*|   \\
  $/$      & \lstinline|/|   \\
  $\%$     & \lstinline|%|   \\
  $<$      & \lstinline|<|   \\
  $>$      & \lstinline|>|   \\
  $\le$    & \lstinline|<=|  \\
  $\ge$    & \lstinline|>=|  \\
  $=$      & \lstinline|=|   \\
  $\ne$    & \lstinline|!=|  \\
  $\wedge$ & \lstinline|&&|  \\
  $\vee$   & \lstinline/!!/ 
\end{tabular}
\end{center}

Here we use built-in \lama binary operators to specify the semantics of $\oplus$; this approach is good enough for now since our primary objective is
to implement a reference interpreter in \lama. Later, when we will deal with \texttt{x86} codegenerator we will refine the understanding of
these operators' semantics.

Note, while the symbols in the first and second columns look similar, they actually have different nature: the left ones are
elements of syntax while the right ones~--- conventional denotations for familiar arithmetic operators.
The last equation in Fig.~\ref{se-denot}, thus, is actually a generic one which denotes \emph{thirteen} concrete equations in which $\otimes$ and $\oplus$ are
substituted coherently according to the table given above.

We can make two important observations.

First, in given semantics there is a single rule for any ``kind'' of expression (variable, constant, binary operation), and for each rule its right part defines
semantic function unambiguously. Thus, for each expression $e$ and each state $\sigma$ there is \emph{at most} one
integer number $y$ such that

\[
  \sembr{e}^\ph_\mathscr{E}\,\sigma=x
\]

This to some extent justifies our desire for $\sembr{e}^\ph_\mathscr{E}$ to be a function from states to integers. Indeed, the
property we just established is \emph{functionality}. On the other hand, in the domain of semantics the same property has
another name: \emph{determinism}. Thus, the semantics in question is deterministic, meaning that evaluating any expression in a given state
delivers at most one value. Non-deterministic semantics, according to which there can be multiple such values, seemingly are not
compatible with our framework of semantic functions; nevertheless, such semantics exist, and there are ways to fix this incompatibility.
Further we will deal only with deterministic semantics. 

Another important property is \emph{compositionality}: the semantics of a construct is expressed in the terms of the semantics
of its proper subconstructs. Indeed, the first two equations are \emph{axioms}, meaning, that no expressions containing semantic
brackets ``$\sembr{\bullet}^\ph_\mathscr{E}$'' occur in the right-hand side; the third equation is not an axiom, but semantic
backets are applied only to proper subconstructs ($e_1$ and $e_2$) of the construct in question ($e$). Compositionality is
a distinctive property of denotational semantics; using other semantic description styles may or may not result in compositional
semantic specification.

When a semantic is compositional, a certain proof principle~--- \emph{structural induction}~--- can be used to establish
its properties. This technique is essentially a specific kind of mathematical induction applied to \emph{finite trees} rather than to
natural numbers. To prove by structural induction that some property holds for all trees one needs to prove, first, that this
property holds for all leaves (\emph{base of induction}); then, assuming that the property holds for all trees up to a certain
height (\emph{induction hypothesis}) one needs to prove that the property holds for all trees one level higher. We demonstrate
the application of this principle by the following example.

\subsection{Strictness}

We are going to prove the \emph{strictness} property of given semantics. It informally means that in order to calculate the
value for the whole expression one needs to calculate the values for all its subexpressions. First, we define the
following relation ``$\preceq$'' of one expression being a subexpression of another:

\[
\begin{array}{c}
  e^\prime \preceq e^\prime\otimes e \\
  e^\prime \preceq e\otimes e^\prime \\
  e\preceq e \\
  e^\prime\preceq e^{\prime\prime} \wedge e^{\prime\prime}\preceq e \Rightarrow e^\prime\preceq e
\end{array}  
\]

The first two lines define the \emph{immediate} subexpression relation while the last two~--- its \emph{reflexive-transitive}
closure. For example, for the expression $(x+2)*y$ all its subexpression are $(x+2)*y$, $x+2$, $y$, $x$, and $2$. 

\begin{lemma}[Strictness]
  For all $e$, $\sigma$ and $x$ if

  \[
  \sembr{e}^\ph_\mathscr{E}\,\sigma=x
  \]

  then for all $e^\prime\preceq e$ there exists $x^\prime$ such that

  \[
  \sembr{e^\prime}^\ph_\mathscr{E}\,\sigma=x^\prime
  \]
\end{lemma}
\begin{proof}
  For base case (variable and constant) the lemma holds vacuously since in both cases
  the only possible subexpressions are these expressions themselves.

  Assume the lemma holds for $e_1$ and $e_2$; we need to prove it holds for $e_1\otimes e_2$.
  By the definition of ``$\preceq$'' for any $e^\prime\preceq e_1\otimes e_2$ one of the
  following is true:

  \begin{enumerate}
  \item $e^\prime=e_1$, or
  \item $e^\prime=e_2$, or
  \item $e^\prime\preceq e_1$, or
  \item $e^\prime\preceq e_1$.
  \end{enumerate}

  By the condition of lemma we have $\sembr{e_1\otimes e_2}^\ph_\mathscr{E}\,\sigma=x$.
  By the definitiono of $\sembr{\bullet}^\ph_\mathscr{E}$ we have $\sembr{e_1}^\ph_\mathscr{E}\,\sigma\oplus\sembr{e_2}^\ph_\mathscr{E}\,\sigma=x$.
  By the definition of $\oplus$ there exist $x_1$ and $x_2$ such that

  \[
  \begin{array}{rcl}
    \sembr{e_1}^\ph_\mathscr{E}\,\sigma&=&x_1\\
    \sembr{e_2}^\ph_\mathscr{E}\,\sigma&=&x_2
  \end{array}
  \]

  If $e^\prime=e_1$ or $e^\prime=e_2$ then the lemma follows immediately.
  If $e^\prime\preceq e_1$ (or $e^\prime\preceq e_2$) the induction hypothesis can be applied as we just have proven that
  both $e_1$ and $e_2$ have some values being evaluated in the state $\sigma$.
\end{proof}

The strictness property, in particular, means that if variable $x$ is undefined in some state $\sigma$, then
any expression $e$, containing $x$, is also undefined in $\sigma$. Indeed, if $x$ occurs in $e$, then, naturally,
$x\preceq e$. If $\sigma\,x$ undefined but $\sembr{e}^\ph_\mathscr{E}\,\sigma$ not, this would contradict
the lemma we've just proven.

Now we can give precise answers to the questions asked in section~\ref{intro-semantics}.
The first question was if the expression \lstinline|0*(x/0)| evaluates to zero or undefined. Due to the strictness of our semantics it is undefined in
any state. Indeed

\[
\mbox{\lstinline|x/0|}\preceq \mbox{\lstinline|0*(x/0)|}
\]

and $\sembr{\mbox{\lstinline|x/0|}}^\ph_\mathscr{E}\,\sigma$ is
undefined for any state $\sigma$ since either \lstinline[mathescape=true]|$\sigma\,$x| is undefined or
\lstinline[mathescape=true]|$\sigma\,$x| is defined but \lstinline[mathescape=true]|$\sigma\,$x / 0| is
undefined due to the division by zero.

The second question was if \lstinline|1+x-x| is equivalent to \lstinline|1|. Again, by the strictness and the
fact that $\mbox{\lstinline|x|}\preceq\mbox{\lstinline|1+x-x|}$ we immediately have that for the \emph{empty state}
$\Lambda$, undefined for every variable $x$, $\sembr{1}^\ph_\mathscr{E}\,\Lambda=1$ but $\sembr{\mbox{\lstinline|1+x-x|}}^\ph_\mathscr{E}\,\Lambda$ is undefined.
Thus, these two expressions are not equivalent.

We stress that these answers are specific to the concrete semantics of expressions we described; for different semantics the answers can be different.

\section{Statements}

The other syntactic category of the straight line programs language is \emph{statements}. Its abstract syntax is given by the following
description:

\[
\renewcommand{\arraystretch}{1}
\begin{array}{rcl}  
  \mathscr S & = & \mbox{\lstinline|skip|} \\
             &   & \mathscr X \mbox{\lstinline|:=|} \;\mathscr E \\
             &   & \mbox{\lstinline|read (|} \mathscr X \mbox{\lstinline|)|} \\
             &   & \mbox{\lstinline|write (|} \mathscr E \mbox{\lstinline|)|} \\
             &   & \mathscr S \mbox{\lstinline|;|} \mathscr S
\end{array}
\]

Here $\mathscr E$ and $\mathscr X$ stand for the sets of expressions and variables, as in the previous section. The first four lines of abstract
syntax description define four \emph{primitive} statements: empty, assignment, input and output respectively. The fifth one makes it possible to
combine primitive statements info compositions. The order and subordination of composition counterparts strictly speaking is essential, thus

\begin{lstlisting}
   read (x); (y := x+4; write (y))
\end{lstlisting}

and

\begin{lstlisting}
   (read (x); y := x+4); write (y)
\end{lstlisting}

are different statements; we use here brackets as elements of concrete syntax to reflect the grouping of subtrees in abstract syntax tree.
To reduce the use of brackets we assume that composition by default associates to the \emph{right} (i.e. as in the former example).

\subsection{Big-Step Operational Semantics}

Our next step is to define the semantics for statements. First, as always, we need to specify the semantic domain for statements' semantics.
From the syntactic form of statements it should be clear that we are dealing with a language with \emph{side effects}: there are read and write statements,
which, presumably, communicate with outer world, and assignment, which, presumably, changes the values of variables. These two kinds of side effects
play different roles: while read and write make the effect of a program execution \emph{externally observable}, assignments define internal behavior.
Thus, essentially different by their internal behavior programs can be indistinguishable while observed externally. We reflect this consideration by
choosing the semantic domain to be a set of functions from input streams of integers to output streams of integers

\[
\mathbb{Z}^*\to\mathbb{Z}^*
\]

We call the pair of input-output streams \emph{world} and define the set of all worlds to be

\[
  \mathscr W = \mathbb Z^* \times \mathbb Z^*
\]

For simplicity, we define the following operations for worlds:

\[
\begin{array}{rcl}
  \primi{read}\,{\inbr{xi,\,o}}    & = & \inbr{x,\,\inbr{i,\,o}}\\
  \primi{write}\,{x\,\inbr{i,\,o}} & = & \inbr{i,\,ox}\\
  \primi{out}\,{\inbr{i,\,o}}      & = & o
\end{array}
\]

The first one, ``$\primi{read}$'', takes a world in which input stream $xi$ contains at least one element $x$ and returns a pair of elements: $x$ and the residual
word with the first element of input stream removed. The next one, ``$\primi{write}$'', to some extent does the opposite: it takes some number $x$ and a world and
returns a world in which this number is appended to the end of the output stream. Finally, ``$\primi{out}$'' just returns the output stream of a given world.

\setarrow{\xRightarrow}
\setsubarrow{^\ph_{\mathscr S}}

\begin{figure}[t]
  \[
  \def\arraystretch{3}
  \arraycolsep=5pt
  \begin{array}{cr}
    \trans{c}{\llang{skip}}{c} & \ruleno{Skip}\\
    \trans{\inbr{\sigma,\, \omega}}{\llang{x := $\;\;e$}}{\inbr{\sigma\,[x\gets\sembr{e}^\ph_{\mathscr E}\;\sigma],\,\omega}} & \ruleno{Assign} \\
    \trule{\inbr{z,\,\omega^\prime}=\primi{read}{\,\omega}}
          {\trans{\inbr{\sigma,\, \omega}}{\llang{read ($x$)}}{\inbr{\sigma\,[x\gets z],\,\omega^\prime}}} & \ruleno{Read} \\[5mm]
    \trans{\inbr{\sigma,\, \omega}}{\llang{write ($e$)}}{\inbr{\sigma,\, \primi{write}{\,(\sembr{e}^\ph_{\mathscr E}\;\sigma)\, \omega}}}& \ruleno{Write} \\
    \trule{\begin{array}{cc}
              \trans{c_1}{s_1}{c^\prime} & \trans{c^\prime}{s_2}{c_2}
           \end{array}}
          {\trans{c_1}{s_1\llang{;}s_2}{c_2}} & \ruleno{Seq}
  \end{array}
  \]
\caption{Big-step operational semantics for statements}
\label{bs_stmt}
\end{figure}

To define the semantics we could use the denotational style as we did for expressions, and it would work just fine. However, as our language starts to evolve,
the denotational style will be harder to adjust to meet our intentions; in addition studying yet another way for semantics' specification would make us more
versatile.

The technique we are going to use is called \emph{big-step operational semantics}. Unlike denotational case, where a semantic object
is immediately given for each syntactic form, operational style involves the construction of intermediate \emph{evaluation relation}, which we
denote ``$\transrel$''. From the semantics of expressions we already know the notion of state and how to calculate the
values of expressions in given states. Thus, each statement modifies an \emph{enriched} state which consists of a regular state and a world. We call this
enriched state \emph{configuration} and define the set of all configurations to be

\[
\mathscr{C} = St \times \mathscr W
\]

Evaluation relation connects a statement and two configurations: \emph{initial} and \emph{final}:

\[
\transrel\subseteq \mathscr{C}\times\mathscr{S}\times\mathscr{C}
\]

We will use infix notation to denote the elements of evaluation relation: instead of 

\[
\inbr{c_1,\,s,\,c_2}\in\transrel
\]

we will use the form


\[
\trans{c_1}{s}{c_2}
\]


where $c_1,\,c_2\in\mathscr{C}$ and $s\in\mathscr{S}$. The informal meaning of this notation is
``the evaluation of a statement $s$ in a configuration $c_1$ completes with the configuration $c_2$''.

The relation ``$\transrel$'' is defined by the following deductive system (see Fig.~\ref{bs_stmt}). The system
consists of five rules each of which has the following generic form

\[
\dfrac{\mbox{\emph{premise}}\dots\mbox{\emph{premise}}}{\mbox{\emph{conclusion}}}
\]

The informal meaning of a rule is that the conclusion holds under the condition that all the premises hold. As
we use this system to define the relation ``$\transrel$'' the conclusions of the rules always have
the form

\[
\trans{c_1}{s}{c_2}
\]

for some $c_1,\,c_2$ and $s$. Sometimes a rule does not contain premises, or there is no premise which
contains ``$\transrel$''; such rules are called \emph{axioms}. Finally, we mark each rule with
a label on the right for reference; these labels are not a part of the deductive system and play
role of comments.

We now give detailed comments for each rule to explain the whole idea of using a deductive system to
specify semantics in whole, and big-step operational semantics in particular.

The first rule, $\rulename{Skip}$, defines the semantics of the \lstinline|skip| statement. It is an
axiom which tells us that the evaluation of \lstinline|skip| statement does not change the configuration.

The next one, $\rulename{Assign}$, deals with assignments. It is also an axiom, which tells us that an
assignment never changes a world (notice the second component of configuration, which is left unchanged).
As for the state component, first, we evaluate the value of expression $e$ in given state $\sigma$ using
the semantics for expressions $\sembr{\bullet}^\ph_\mathscr{E}$, defined in the previous section. Then we
substitute the value for variable $x$ in the state with calculated value using the primitive $\bullet\,[\bullet\gets \bullet]$
which has the following definition:

\[
\sigma\,[x\gets v]\,y=\left\{\begin{array}{rcl}
                                \sigma\,y & , & y \ne x\\
                                v & , & y = x
                             \end{array}
                   \right.
\]

Thus, for a state $\sigma$, variable $x$, and value $v$ the state $\sigma\,[x\gets v]$ assigns $v$ to $x$ and leaves other
variables unchanged.

Two next rules, $\rulename{Read}$ and $\rulename{Write}$, describe the semantics for \lstinline|read| and
\lstinline|write| constructs. In both cases the definitions use corresponding primitives for worlds: in $\rulename{Read}$
we extract the next value $z$ (if any) from the input stream and return the modified state, in which the variable being
read is associated with $z$, and remaining world. In $\rulename{Write}$ we first calculate the value of the expression
being written in current state and put it into the output stream of the word. Note, both rules are axioms as well:
although $\rulename{Read}$ has a premise, this premise does not contain ``$\transrel$''.

Finally, the last rule $\rulename{Seq}$ prescribes the semantics for the sequential composition. This time it is
not an axiom, and it tell us that in order to evaluate the composition of two statements we first need to
evaluate the first one, obtaining some intermediate configuration $c^\prime$, and then the second one, using
this intermediate configuration as input. Note, the order of evaluation is defined not by the order of
premises, but by their nature: regardless the order in which the premises are given it is impossible
to calculate $c_2$ unless $c^\prime$ is calculated first.

With the relation ``$\transrel$'' defined we can abbreviate the ``surface'' semantics for the language of statements:

\[
\trule{\trans{\inbr{\Lambda,\,\inbr{i,\,\epsilon}}}{s}{\inbr{\sigma,\,\omega}}}
      {\sembr{s}^\ph_{\mathscr S}\,i=\primi{out}{\,\omega}}\eqno{(\star)}
\]

This rule (which is \emph{not} a part of big-step operational semantics) establishes a connection between
evaluation relation ``$\transrel$'' and the semantics for statements $\sembr{\bullet}^\ph_\mathscr{S}$. In order
to calculate the output stream for given input sream $i$ we first construct an initial configuration

\[
\inbr{\Lambda,\,\inbr{i,\,\epsilon}}
\]

(remember, $\Lambda$ stands for the empty state), then calculate the final configuration $\inbr{\sigma,\,\omega}$ using
the evaluation relation, and then extract the output stream of the final world.

Similarly to the denotational case, we can formulate two properties of given semantics:

\begin{itemize}
\item \emph{Determinism}: given arbitrary $c\in\mathscr{C}$ and $s\in\mathscr{S}$ there exists at most one $c^\prime\in\mathscr{C}$ such that

  \[
  \trans{c}{s}{c^\prime}
  \]

  Indeed, we can see that for each kind of statement and for each initial configurations there is at most one applicable rule.

\item \emph{Compositionality}: for each non-axiom rule (this time, only $\rulename{Seq}$) in all its premises only
  a proper subconstructs of the conclusion construct are used (this time, $s_1$ and $s_2$ of $s_1\llang{;}\,s_2$). Hence,
  the principle of structural induction can be used to prove the properties of the semantics.
\end{itemize}

We now show by example how big-step operational semantics works. Let us have the following program

\begin{lstlisting}
   read (x); read (y); z := x + y; write (z)
\end{lstlisting}

and let the input stream be $\inbr{2,\,3}$. First, according to $(\star)$, we construct an initial configuration
and write down what we currently know about the evaluation relation:

\[
\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}
\]

We do not know yet what to put instead of $\fbox{?}$. To figure it out we need to seek for applicable rule. It turns
out that the only one rule can be applied, namely $\rulename{Seq}$ (remember, ``\lstinline|;|'' associates to
the right). So, we can move one floor up by applying the rule and filling in the parts we already know
so far:

\[
\trule{\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x)}}{\fbox{??}}\quad\trans{\fbox{??}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
      {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

In addition to unknown configuration ``$\fbox{?}$'' we now have another one, ``$\fbox{??}$''. But, now we can apply rule $\rulename{Read}$ to the
first premise, which immediately lets us calculate what ``$\fbox{??}$'' is:

\[
\trule{\trule{\inbr{2,\,\inbr{\inbr{3},\,\epsilon}}=\primi{read}{\,\inbr{\inbr{2,\,3},\,\epsilon}}}
             {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x)}}{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}}\quad
       \dots}
      {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

Now we can proceed with the second premise:

\[
\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}
\]

Again, we can move one floor up by using the rule $\rulename{Seq}$ (and only it):

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y)}}{\fbox{???}}\quad\trans{\fbox{???}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
      {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

And, again, we can apply the rule $\rulename{Read}$ to the first premise, which gives us the value for ``$\fbox{???}$'':

\[
\trule{\trule{\inbr{3,\,\inbr{\epsilon,\,\epsilon}}=\primi{read}{\,\inbr{\inbr{3},\,\epsilon}}}
             {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y)}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}}\quad
       \dots}
      {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

Moving to the second premise and applyng the rule $\rulename{Seq}$ gives us

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y}}{\fbox{????}}\quad\trans{\fbox{????}}{\llang{write (z)}}{\fbox{?}}}
      {\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
\]

which makes it possible to apply the rule $\rulename{Assign}$ (we left the reader to confirm that $\sembr{\llang{x+y}}^\ph_\mathscr{E}\,[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3]=5$):

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\epsilon}}}\quad
       \dots}
      {\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
\]

This gives us the value for ``$\fbox{????}$'', which allows us to finally calculate ``$\fbox{?}$'' using the axiom $\rulename{Write}$:

\[
\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\epsilon}}}{\llang{write (z)}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\inbr{5}}}}
\]

Thus, taking into account $(\star)$ yet again, we have

\[
\sembr{\llang{read (x); read (y); z := x + y; write (z)}}^\ph_\mathscr{S}\,\inbr{2,\,3}=5
\]

We can see that big-step operational semantics allows us to perform program evaluation for concrete input: we just form an initial configuration for this input and then
systematically apply rules of the semantics until (and if) we come to the result of the evaluation. The application of an axiom completes in one
step (we can immediately evaluate the result configuration); the application of the rule for sequential composition amounts to splitting the composite
statement into two, moving one floor up in the semantics's rule, and repeat. In the process a certain structure, called \emph{derivation tree}, is
maintained implicitly. The nodes of a derivation tree are \emph{instances} of the semantics' rules, the edges connect premises with conclusions. The derivation
tree for the example we just considered is depictured in Fig.~\ref{derivation-tree} (the program's statements are omitted due to space considerations). Additionally
to the derivation tree itself a configuration calculation flow is shown explicitly by dashed arrows. We can see, that for axioms these arrows come directly from
left- to right-hand part of the rules, while the rule for composition threads configurations from right-hard part of one rule to the left-hand part of another.

Besides evaluation big-step operational semantics can also be used to \emph{prove} the properties of the programs. For example, we can prove, that for
arbitrary $n,\, m\in\mathbb{N}$ 

\[
\sembr{\llang{read (x); read (y); z := x + y; write (z)}}^\ph_\mathscr{S}\,\inbr{n,\,m}=n+m
\]

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.8]{images/03-01.eps}
  \caption{Derivation tree example}
  \label{derivation-tree}
\end{figure}
\FloatBarrier

Indeed, we just need to repeat the construction of the derivation tree as we did in the evluation case, but this time instead of concrete numbers use
their abstract denotations $n$ and $m$; all steps could be performed as before until we arrive at the assignment rule. This time we would need to prove
an additional lemma

\[
\sembr{\llang{x + y}}^\ph_\mathscr{E}\,[\llang{x}\mapsto n,\,\llang{y}\mapsto m]=n+m
\]

which, of course, can be easily done by unfolding corresponding rule for $\sembr{\bullet}^\ph_\mathscr{E}$.

And, besides proving the properties of \emph{concrete programs}, big-step operational semantics can be used to prove the properties
of the semantics of the \emph{language} as whole. We consider some examples in the next section.

\subsection{Properties of the Semantics}






