\chapter{Straight Line Programs}

In this chapter we introduce the language of \emph{straight line} programs which can be considered as a smallest
non-trivial subset of \lama. In this subset all programs are executed sequentially statement by statement with
no branching. Thus, any program either comes to an end or stops due to an error, but cannot loop forever. We
use this simple language to showcase all the ingredients of our approach to language description: abstract and
concrete syntax specification, denotational and operational semantics, etc. We also introduce some components of
the compiler we will be working on: source-level interpreter, stack machine compiler and interpreter, and
\texttt{x86} code generator.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.7]{images/02-01.eps}
  \caption{Abstract Syntax for Expressions}
  \label{expression-syntax}
\end{figure}

\section{Expressions}


Syntactically, our language encorporates two \emph{syntactic categories}: expressions and statements. We start from describing
so-called \emph{abstract syntax} for the expression category. We consider a countable set of \emph{variables}

\[
\mathscr{X}=\{x_1,\,x_2,\,\dots\}
\]

and a set of \emph{binary operators}

\[
\otimes= \{+,\, -,\, \times,\, /,\, \%,\, <,\, \le,\, >,\, \ge,\, =,\,\ne,\, \vee,\, \wedge\}
\]

which contains all thirteen built-in \lama operators. Then, the category of expressions $\mathscr{E}$ can be defined by
the following recursive scheme:

\[
\begin{array}{rcl}
  \mathscr{E} & = & \mathscr{X} \\
              &   & \mathbb{N} \\
              &   & \mathscr{E}\otimes\mathscr{E}
\end{array}
\]

This scheme defines a countable set of \emph{labeled ordered trees} of finite height: each node of such a tree is labeled, and for any node the order
of its immediate subtrees is essential. The simplest trees of this form are just leaves labeled with either variables or natural numbers; we simply
write $\mathscr{X}$ or $\mathbb{N}$ in the first two lines of definition of $\mathscr{E}$, but actually we mean tree nodes \emph{labeled} by the symbols of
these sets. As for the third line, it stipulates that for arbitrary two expressions $e_1,\,e_2\in\mathscr{E}$ a tree with a root labeled with any symbol
from $\otimes$ and immediate subtress $e_1$ and $e_2$ is also expression (see Fig.~\ref{expression-syntax}).

We call this definition \emph{abstract} syntax because it describes nothing more than a subordination between elementary constructs. In order to represent
expressions in some medium, however, we need \emph{concrete} syntax; it is easy to anticipate that there can be multiple concrete syntaxes for given
abstract one. In Fig.~\ref{expression-concrete} we give some examples of those for expressions: the first (\emph{a}) consists of graphical elements such as
circles, lines, texts, etc. Another one (\emph{b}) is the familiar \emph{infix notation} which includes numbers, letters, binary
operators and brackets. Yet another (but by no means the last one) is \emph{reverse Polish notation} (\emph{c}), in which binary operators are
put \emph{after} the operands they connect. In what follows we will stick with infix notation.

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.7]{images/02-02.eps}
  \caption{Various Concrete Syntaxes for Expression Language}
  \label{expression-concrete}
\end{figure}

Now we need to define the semantic domain for the semantics of expressions. We already hinted that this domain should be shaped like a set of some
data processing functions $\mathfrak{D}\to\mathfrak{D}$; however, we need to be more specific.

As we deal with arithmetic expressions it is rather natural to expect that the results of their evaluation are interger values, i.e. $\mathbb{Z}$ (as we agreed
earlier, we assume $\mathbb{Z}\subset\mathfrak{D}$); on the other hand, the value of an expression depends on the values of variables it contains. We can
encode these values as a \emph{state}~--- a function which maps variables to integer values:

\[
St : \mathscr{X} \to \mathbb{Z}
\]

There is nothing wrong with assuming $St\subset\mathfrak{D}$: as any expression can contain only a finite number of variables we are interested only in
states with finite domains which can be encoded, for example, as finite lists of pairs. Thus, finally, we have the following ``type'' for the semantics
of expressions:

\[
\sembr{\bullet}^\ph_\mathscr{E}:\mathscr{E}\to(St\to\mathbb{Z})
\]

\subsection{Denotational Semantics}

There are multiple ways to give the semantics for a language formally. Here we use so-called \emph{denotational} way in which it is immediately
specified what object from the semantic domain corresponds to a given language construct. For this concrete language denotational semantics
looks simple and natural; however, for more advanced languages more advanced mathematical apparatus would be required. It is also worth mentioning that,
as a rule, denotational semantics gives us a very abstract, high-level view on the behavior of programs, which may or may not be desirable from a
practical standpoint.


\begin{figure}[t]
\[
\begin{array}{rcl}
  \sembr{z}^\ph_\mathscr{E} & = & \sigma \mapsto z \\  
  \sembr{x}^\ph_\mathscr{E} & = & \sigma \mapsto \sigma\,x \\
  \sembr{e_1\otimes e_2}^\ph_\mathscr{E} & = & \sigma \mapsto \sembr{e_2}^\ph_\mathscr{E}\,\sigma\oplus\sembr{e_2}^\ph_\mathscr{E}\,\sigma
\end{array}
\]
\caption{Denotational Semantics of Expressions}
\label{se-denot}
\end{figure}


The denotational semantics for expressions is shown in Fig.~\ref{se-denot}.
We give here three equations, one for each syntactic form. In the right-hand side of each equation we immediately
give the object (a function from states to integers) which corresponds to the semantics of the expression in the
left-hand side. The notation $\star \mapsto \bullet$ is used to denote a function from $\star$ to $\bullet$; we refrain from
using the lambda notation since these functions are elements of the \emph{meta-language} (the language we use to describe the
semantics), not of the \emph{object} one (the language which semantics is being described).

In the first equation, when the expression is a natural number $z$, its semantics is a constant function, which for
any state $\sigma$ return just this number $z$.

When the expression in question is a variable $x$, its semantics is a function which, given a state $\sigma$, returns
the value this state assigns to this variable.

Finally, when the expression is a binary operator with two subexpressions $e_1$ and $e_2$, its semantics is a function which, given a state $\sigma$,
first calcalates the values of subexpressions $e_1$ and $e_2$ in the same state, and then combines them using a certain arithmetic operator $\oplus$.
The correspondence between $\otimes$ and $\oplus$ is described by the following table:

\begin{center}
\begin{tabular}{c|cl}
  $\otimes$     & $\oplus$ in \lama\\
  \hline
  $+$      & \lstinline|+|   \\
  $-$      & \lstinline|-|   \\
  $\times$ & \lstinline|*|   \\
  $/$      & \lstinline|/|   \\
  $\%$     & \lstinline|%|   \\
  $<$      & \lstinline|<|   \\
  $>$      & \lstinline|>|   \\
  $\le$    & \lstinline|<=|  \\
  $\ge$    & \lstinline|>=|  \\
  $=$      & \lstinline|=|   \\
  $\ne$    & \lstinline|!=|  \\
  $\wedge$ & \lstinline|&&|  \\
  $\vee$   & \lstinline/!!/ 
\end{tabular}
\end{center}

Here we use built-in \lama binary operators to specify the semantics of $\oplus$; this approach is good enough for now since our primary objective is
to implement a reference interpreter in \lama. Later, when we will deal with \texttt{x86} codegenerator we will refine the understanding of
these operators' semantics.

Note, while the symbols in the first and second columns look similar, they actually have different nature: the left ones are
elements of syntax while the right ones~--- conventional denotations for familiar arithmetic operators.
The last equation in Fig.~\ref{se-denot}, thus, is actually a generic one which denotes \emph{thirteen} concrete equations in which $\otimes$ and $\oplus$ are
substituted coherently according to the table given above.

We can make two important observations.

First, in given semantics there is a single rule for any ``kind'' of expression (variable, constant, binary operation), and for each rule its right part defines
semantic function unambiguously. Thus, for each expression $e$ and each state $\sigma$ there is \emph{at most} one
integer number $y$ such that

\[
  \sembr{e}^\ph_\mathscr{E}\,\sigma=x
\]

This to some extent justifies our desire for $\sembr{e}^\ph_\mathscr{E}$ to be a function from states to integers. Indeed, the
property we just established is \emph{functionality}. On the other hand, in the domain of semantics the same property has
another name: \emph{determinism}. Thus, the semantics in question is deterministic, meaning that evaluating any expression in a given state
delivers at most one value. Non-deterministic semantics, according to which there can be multiple such values, seemingly are not
compatible with our framework of semantic functions; nevertheless, such semantics exist, and there are ways to fix this incompatibility.
Further we will deal only with deterministic semantics. 

Another important property is \emph{compositionality}: the semantics of a construct is expressed in the terms of the semantics
of its proper subconstructs. Indeed, the first two equations are \emph{axioms}, meaning, that no expressions containing semantic
brackets ``$\sembr{\bullet}^\ph_\mathscr{E}$'' occur in the right-hand side; the third equation is not an axiom, but semantic
backets are applied only to proper subconstructs ($e_1$ and $e_2$) of the construct in question ($e$). Compositionality is
a distinctive property of denotational semantics; using other semantic description styles may or may not result in compositional
semantic specification.

When a semantic is compositional, a certain proof principle~--- \emph{structural induction}~--- can be used to establish
its properties. This technique is essentially a specific kind of mathematical induction applied to \emph{finite trees} rather than to
natural numbers. To prove by structural induction that some property holds for all trees one needs to prove, first, that this
property holds for all leaves (\emph{base of induction}); then, assuming that the property holds for all trees up to a certain
height (\emph{induction hypothesis}) one needs to prove that the property holds for all trees one level higher. We demonstrate
the application of this principle by the following example.

\subsection{Strictness}

We are going to prove the \emph{strictness} property of given semantics. It informally means that in order to calculate the
value for the whole expression one needs to calculate the values for all its subexpressions. First, we define the
following relation ``$\preceq$'' of one expression being a subexpression of another:

\[
\begin{array}{c}
  e^\prime \preceq e^\prime\otimes e \\
  e^\prime \preceq e\otimes e^\prime \\
  e\preceq e \\
  e^\prime\preceq e^{\prime\prime} \wedge e^{\prime\prime}\preceq e \Rightarrow e^\prime\preceq e
\end{array}  
\]

The first two lines define the \emph{immediate} subexpression relation while the last two~--- its \emph{reflexive-transitive}
closure. For example, for the expression $(x+2)*y$ all its subexpression are $(x+2)*y$, $x+2$, $y$, $x$, and $2$. 

\begin{lemma}[Strictness]
  For all $e$, $\sigma$ and $x$ if

  \[
  \sembr{e}^\ph_\mathscr{E}\,\sigma=x
  \]

  then for all $e^\prime\preceq e$ there exists $x^\prime$ such that

  \[
  \sembr{e^\prime}^\ph_\mathscr{E}\,\sigma=x^\prime
  \]
\end{lemma}
\begin{proof}
  For base case (variable and constant) the lemma holds vacuously since in both cases
  the only possible subexpressions are these expressions themselves.

  Assume the lemma holds for $e_1$ and $e_2$; we need to prove it holds for $e_1\otimes e_2$.
  By the definition of ``$\preceq$'' for any $e^\prime\preceq e_1\otimes e_2$ one of the
  following is true:

  \begin{enumerate}
  \item $e^\prime=e_1$, or
  \item $e^\prime=e_2$, or
  \item $e^\prime\preceq e_1$, or
  \item $e^\prime\preceq e_1$.
  \end{enumerate}

  By the condition of lemma we have $\sembr{e_1\otimes e_2}^\ph_\mathscr{E}\,\sigma=x$.
  By the definitiono of $\sembr{\bullet}^\ph_\mathscr{E}$ we have $\sembr{e_1}^\ph_\mathscr{E}\,\sigma\oplus\sembr{e_2}^\ph_\mathscr{E}\,\sigma=x$.
  By the definition of $\oplus$ there exist $x_1$ and $x_2$ such that

  \[
  \begin{array}{rcl}
    \sembr{e_1}^\ph_\mathscr{E}\,\sigma&=&x_1\\
    \sembr{e_2}^\ph_\mathscr{E}\,\sigma&=&x_2
  \end{array}
  \]

  If $e^\prime=e_1$ or $e^\prime=e_2$ then the lemma follows immediately.
  If $e^\prime\preceq e_1$ (or $e^\prime\preceq e_2$) the induction hypothesis can be applied as we just have proven that
  both $e_1$ and $e_2$ have some values being evaluated in the state $\sigma$.
\end{proof}

The strictness property, in particular, means that if variable $x$ is undefined in some state $\sigma$, then
any expression $e$, containing $x$, is also undefined in $\sigma$. Indeed, if $x$ occurs in $e$, then, naturally,
$x\preceq e$. If $\sigma\,x$ undefined but $\sembr{e}^\ph_\mathscr{E}\,\sigma$ not, this would contradict
the lemma we've just proven.

Now we can give precise answers to the questions asked in section~\ref{intro-semantics}.
The first question was if the expression \lstinline|0*(x/0)| evaluates to zero or undefined. Due to the strictness of our semantics it is undefined in
any state. Indeed

\[
\mbox{\lstinline|x/0|}\preceq \mbox{\lstinline|0*(x/0)|}
\]

and $\sembr{\mbox{\lstinline|x/0|}}^\ph_\mathscr{E}\,\sigma$ is
undefined for any state $\sigma$ since either \lstinline[mathescape=true]|$\sigma\,$x| is undefined or
\lstinline[mathescape=true]|$\sigma\,$x| is defined but \lstinline[mathescape=true]|$\sigma\,$x / 0| is
undefined due to the division by zero.

The second question was if \lstinline|1+x-x| is equivalent to \lstinline|1|. Again, by the strictness and the
fact that $\mbox{\lstinline|x|}\preceq\mbox{\lstinline|1+x-x|}$ we immediately have that for the \emph{empty state}
$\Lambda$, undefined for every variable $x$, $\sembr{1}^\ph_\mathscr{E}\,\Lambda=1$ but $\sembr{\mbox{\lstinline|1+x-x|}}^\ph_\mathscr{E}\,\Lambda$ is undefined.
Thus, these two expressions are not equivalent.

We stress that these answers are specific to the concrete semantics of expressions we described; for different semantics the answers can be different.

\section{Statements}

The other syntactic category of the straight line programs language is \emph{statements}. Its abstract syntax is given by the following
description:

\[
\renewcommand{\arraystretch}{1}
\begin{array}{rcl}  
  \mathscr S & = & \mbox{\lstinline|skip|} \\
             &   & \mathscr X \mbox{\lstinline|:=|} \;\mathscr E \\
             &   & \mbox{\lstinline|read (|} \mathscr X \mbox{\lstinline|)|} \\
             &   & \mbox{\lstinline|write (|} \mathscr E \mbox{\lstinline|)|} \\
             &   & \mathscr S \mbox{\lstinline|;|} \mathscr S
\end{array}
\]

Here $\mathscr E$ and $\mathscr X$ stand for the sets of expressions and variables, as in the previous section. The first four lines of abstract
syntax description define four \emph{primitive} statements: empty, assignment, input and output respectively. The fifth one makes it possible to
combine primitive statements info compositions. The order and subordination of composition counterparts strictly speaking is essential, thus

\begin{lstlisting}
   read (x); (y := x+4; write (y))
\end{lstlisting}

and

\begin{lstlisting}
   (read (x); y := x+4); write (y)
\end{lstlisting}

are different statements; we use here brackets as elements of concrete syntax to reflect the grouping of subtrees of abstract syntax tree.
To reduce the use of brackets we assume that composition by default associates to the \emph{right} (i.e. as in the former example).

\subsection{Big-Step Operational Semantics}

Our next step is to define the semantics for statements. First, as always, we need to specify the semantic domain.
From the syntactic form of statements it should be clear that we are dealing with the language with \emph{side effects}: there are read and write statements,
which, presumably, communicate with outer world, and assignment, which, presumably, changes the values of variables. These two kinds of side effects
play different roles: while read and write make the effect of a program execution \emph{externally observable}, assignments define internal behavior.
Thus, essentially different by their internal behavior programs can be indistinguishable while observed externally. We reflect this consideration by
choosing the semantic domain to be the set of functions from input streams of integers to output streams of integers

\[
\mathbb{Z}^*\to\mathbb{Z}^*
\]

We call the pair of input-output streams \emph{world} and define the set of all worlds to be

\[
  \mathscr W = \mathbb Z^* \times \mathbb Z^*
\]

For simplicity, we define the following operations for worlds:

\[
\begin{array}{rcl}
  \primi{read}\,{\inbr{xi,\,o}}    & = & \inbr{x,\,\inbr{i,\,o}}\\
  \primi{write}\,{x\,\inbr{i,\,o}} & = & \inbr{i,\,ox}\\
  \primi{out}\,{\inbr{i,\,o}}      & = & o
\end{array}
\]

The first one, ``$\primi{read}$'', takes a world in which input stream $xi$ contains at least one element $x$ and returns a pair of elements: $x$ and the residual
word with the first element of input stream removed. The next one, ``$\primi{write}$'', to some extent does the opposite: it takes some number $x$ and a world and
returns a world in which this number is appended to the end of the output stream. Finally, ``$\primi{out}$'' just returns the output stream of a given world.

\setarrow{\xRightarrow}
\setsubarrow{^\ph_{\mathscr S}}

\begin{figure}[t]
  \[
  \def\arraystretch{3}
  \arraycolsep=5pt
  \begin{array}{cr}
    \trans{c}{\llang{skip}}{c} & \ruleno{Skip}\\
    \trans{\inbr{\sigma,\, \omega}}{\llang{x := $\;\;e$}}{\inbr{\sigma\,[x\gets\sembr{e}^\ph_{\mathscr E}\;\sigma],\,\omega}} & \ruleno{Assign} \\
    \trule{\inbr{z,\,\omega^\prime}=\primi{read}{\,\omega}}
          {\trans{\inbr{\sigma,\, \omega}}{\llang{read ($x$)}}{\inbr{\sigma\,[x\gets z],\,\omega^\prime}}} & \ruleno{Read} \\[5mm]
    \trans{\inbr{\sigma,\, \omega}}{\llang{write ($e$)}}{\inbr{\sigma,\, \primi{write}{\,(\sembr{e}^\ph_{\mathscr E}\;\sigma)\, \omega}}}& \ruleno{Write} \\
    \trule{\begin{array}{cc}
              \trans{c_1}{s_1}{c^\prime} & \trans{c^\prime}{s_2}{c_2}
           \end{array}}
          {\trans{c_1}{s_1\llang{;}s_2}{c_2}} & \ruleno{Seq}
  \end{array}
  \]
\caption{Big-step operational semantics for statements}
\label{bs_stmt}
\end{figure}

To define the semantics we could use the denotational style as we did for expressions, and it would work just fine. However, as our language starts to evolve,
the denotational style will be harder to adjust to meet our intentions; in addition studying yet another way for semantics' specification would make us more
versatile.

The technique we are going to use is called \emph{big-step operational semantics}. Unlike denotational case, where a semantic object
is immediately given for each syntactic form, operational style involves the construction of intermediate \emph{evaluation relation}, which we
denote ``$\transrel$''. From the semantics of expressions we already know the notion of state and how to calculate the
values of expressions in given states. Thus, each statement modifies an \emph{enriched} state which consists of a regular state and a world. We call this
enriched state \emph{configuration} and define the set of all configurations to be

\[
\mathscr{C} = St \times \mathscr W
\]

Evaluation relation connects a statement and two configurations: \emph{initial} and \emph{final}:

\[
\transrel\subseteq \mathscr{C}\times\mathscr{S}\times\mathscr{C}
\]

We will use infix notation to denote the elements of evaluation relation: instead of 

\[
\inbr{c_1,\,s,\,c_2}\in\transrel
\]

we will use the form


\[
\trans{c_1}{s}{c_2}
\]


where $c_1,\,c_2\in\mathscr{C}$ and $s\in\mathscr{S}$. The informal meaning of this notation is
``the evaluation of a statement $s$ in a configuration $c_1$ completes with the configuration $c_2$''. As the
statement $s$ can have arbitrarily complex structure this semantic style is called ``big-step'' since
the evaluation relation ``$\transrel$'' immediately delivers us the final configuration $c_2$ as if
the computations were performed in one big step, without observable subdivision to computations
of smaller components of $s$.

The relation ``$\transrel$'' is defined by the following deductive system (see Fig.~\ref{bs_stmt}). The system
consists of five rules each of which has the following generic form

\[
\dfrac{\mbox{\emph{premise}}\dots\mbox{\emph{premise}}}{\mbox{\emph{conclusion}}}
\]

The informal meaning of a rule is that the conclusion holds under the condition that all the premises hold. As
we use this system to define the relation ``$\transrel$'' the conclusions of the rules always have
the form

\[
\trans{c_1}{s}{c_2}
\]

for some $c_1,\,c_2$ and $s$. Sometimes a rule does not contain premises, or there is no premise which
contains ``$\transrel$''; such rules are called \emph{axioms}. Finally, we mark each rule with
a label on the right for reference; these labels are not a part of the deductive system and play
role of comments.

We now give detailed comments for each rule to explain the whole idea of using a deductive system to
specify semantics in whole, and big-step operational semantics in particular.

The first rule, $\rulename{Skip}$, defines the semantics of the \lstinline|skip| statement. It is an
axiom which tells us that the evaluation of \lstinline|skip| statement does not change the configuration.

The next one, $\rulename{Assign}$, deals with assignments. It is also an axiom, which tells us that an
assignment never changes a world (notice the second component of configuration, which is left unchanged).
As for the state component, first, we evaluate the value of expression $e$ in given state $\sigma$ using
the semantics for expressions $\sembr{\bullet}^\ph_\mathscr{E}$, defined in the previous section. Then we
substitute the value for variable $x$ in the state with calculated value using the primitive $\bullet\,[\bullet\gets \bullet]$
which has the following definition:

\[
\sigma\,[x\gets v]\,y=\left\{\begin{array}{rcl}
                                \sigma\,y & , & y \ne x\\
                                v & , & y = x
                             \end{array}
                   \right.
\]

Thus, for a state $\sigma$, variable $x$, and value $v$ the state $\sigma\,[x\gets v]$ assigns $v$ to $x$ and leaves other
variables unchanged.

Two next rules, $\rulename{Read}$ and $\rulename{Write}$, describe the semantics for \lstinline|read| and
\lstinline|write| constructs. In both cases the definitions use corresponding primitives for worlds: in $\rulename{Read}$
we extract the next value $z$ (if any) from the input stream and return the modified state, in which the variable being
read is associated with $z$, and remaining world. In $\rulename{Write}$ we first calculate the value of the expression
being written in current state and put it into the output stream of the word. Note, both rules are axioms as well:
although $\rulename{Read}$ has a premise, this premise does not contain ``$\transrel$''.

Finally, the last rule $\rulename{Seq}$ prescribes the semantics for the sequential composition. This time it is
not an axiom, and it tells us that in order to evaluate the composition of two statements we first need to
evaluate the first one, obtaining some intermediate configuration $c^\prime$, and then the second one, using
this intermediate configuration as input. Note, the order of evaluation is defined not by the order of
premises, but by their nature: regardless the order in which the premises are given it is impossible
to calculate $c_2$ unless $c^\prime$ is calculated first.

With the relation ``$\transrel$'' defined we can abbreviate the ``surface'' semantics for the language of statements:

\[
\trule{\trans{\inbr{\Lambda,\,\inbr{i,\,\epsilon}}}{s}{\inbr{\sigma,\,\omega}}}
      {\sembr{s}^\ph_{\mathscr S}\,i=\primi{out}{\,\omega}}\eqno{(\star)}
\]

This rule (which is \emph{not} a part of big-step operational semantics) establishes a connection between
evaluation relation ``$\transrel$'' and the semantics for statements $\sembr{\bullet}^\ph_\mathscr{S}$. In order
to calculate the output stream for given input sream $i$ we first construct an initial configuration

\[
\inbr{\Lambda,\,\inbr{i,\,\epsilon}}
\]

(remember, $\Lambda$ stands for the empty state), then calculate the final configuration $\inbr{\sigma,\,\omega}$ using
the evaluation relation, and then extract the output stream of the final world.

Similarly to the denotational case, we can formulate two properties of given semantics:

\begin{itemize}
\item \emph{Determinism}: given arbitrary $c\in\mathscr{C}$ and $s\in\mathscr{S}$ there exists at most one $c^\prime\in\mathscr{C}$ such that

  \[
  \trans{c}{s}{c^\prime}
  \]

  Indeed, we can see that for each kind of statement and for each initial configurations there is at most one applicable rule.

\item \emph{Compositionality}: for each non-axiom rule (this time, only $\rulename{Seq}$) in all its premises only
  proper subconstructs of the conclusion construct are used (this time, $s_1$ and $s_2$ of $s_1\llang{;}\,s_2$). Hence,
  the principle of structural induction can be used to prove the properties of the semantics.
\end{itemize}

We now show by example how big-step operational semantics works. Let us have the following program

\begin{lstlisting}
   read (x); read (y); z := x + y; write (z)
\end{lstlisting}

and let the input stream be $\inbr{2,\,3}$. First, according to $(\star)$, we construct an initial configuration
and write down what we currently know about the evaluation relation:

\[
\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}
\]

We do not know yet what to put instead of $\fbox{?}$. To figure it out we need to seek for applicable rule. It turns
out that the only one rule can be applied, namely $\rulename{Seq}$ (remember, ``\lstinline|;|'' associates to
the right). So, we can move one floor up by applying the rule and filling in the parts we already know
so far:

\[
\trule{\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x)}}{\fbox{??}}\quad\trans{\fbox{??}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
      {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

In addition to unknown configuration ``$\fbox{?}$'' we now have another one, ``$\fbox{??}$''. But, now we can apply rule $\rulename{Read}$ to the
first premise, which immediately lets us calculate what ``$\fbox{??}$'' is:

\[
\trule{\trule{\inbr{2,\,\inbr{\inbr{3},\,\epsilon}}=\primi{read}{\,\inbr{\inbr{2,\,3},\,\epsilon}}}
             {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x)}}{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}}\quad
       \dots}
      {\trans{\inbr{\Lambda,\,\inbr{\inbr{2,\,3},\,\epsilon}}}{\llang{read (x); read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

Now we can proceed with the second premise:

\[
\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}
\]

Again, we can move one floor up by using the rule $\rulename{Seq}$ (and only it):

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y)}}{\fbox{???}}\quad\trans{\fbox{???}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
      {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

And, again, we can apply the rule $\rulename{Read}$ to the first premise, which gives us the value for ``$\fbox{???}$'':

\[
\trule{\trule{\inbr{3,\,\inbr{\epsilon,\,\epsilon}}=\primi{read}{\,\inbr{\inbr{3},\,\epsilon}}}
             {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y)}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}}\quad
       \dots}
      {\trans{\inbr{[\llang{x}\mapsto 2],\,\inbr{\inbr{3},\,\epsilon}}}{\llang{read (y); z := x + y; write (z)}}{\fbox{?}}}
\]

Moving to the second premise and applyng the rule $\rulename{Seq}$ gives us

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y}}{\fbox{????}}\quad\trans{\fbox{????}}{\llang{write (z)}}{\fbox{?}}}
      {\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
\]

which makes it possible to apply the rule $\rulename{Assign}$ (we left the reader to confirm that $\sembr{\llang{x+y}}^\ph_\mathscr{E}\,[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3]=5$):

\[
\trule{\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\epsilon}}}\quad
       \dots}
      {\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3],\,\inbr{\epsilon,\,\epsilon}}}{\llang{z := x + y; write (z)}}{\fbox{?}}}
\]

This gives us the value for ``$\fbox{????}$'', which allows us to finally calculate ``$\fbox{?}$'' using the axiom $\rulename{Write}$:

\[
\trans{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\epsilon}}}{\llang{write (z)}}{\inbr{[\llang{x}\mapsto 2,\,\llang{y}\mapsto 3,\,\llang{z}\mapsto 5],\,\inbr{\epsilon,\,\inbr{5}}}}
\]

Thus, taking into account $(\star)$ yet again, we have

\[
\sembr{\llang{read (x); read (y); z := x + y; write (z)}}^\ph_\mathscr{S}\,\inbr{2,\,3}=5
\]

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.8]{images/03-01.eps}
  \caption{Derivation tree example}
  \label{derivation-tree}
\end{figure}

We can see that big-step operational semantics allows us to perform program evaluation for concrete input: we just form an initial configuration for this input and then
systematically apply rules of the semantics until (and if) we come to the result of the evaluation. The application of an axiom completes in one
step (we can immediately evaluate the result configuration); the application of the rule for sequential composition amounts to splitting the composite
statement into two, moving one floor up in the semantics's rule, and repeat. In the process a certain structure, called \emph{derivation tree}, is
maintained implicitly. The nodes of a derivation tree are \emph{instances} of the semantics' rules, the edges connect premises with conclusions. The derivation
tree for the example we just considered is depictured in Fig.~\ref{derivation-tree} (the program's statements are omitted due to space considerations). Additionally
to the derivation tree itself a configuration calculation flow is shown explicitly by dashed arrows. We can see, that for axioms these arrows come directly from
left- to right-hand part of the rules, while the rule for composition threads configurations from right-hard part of one rule to the left-hand part of another.

\FloatBarrier

Besides evaluation big-step operational semantics can also be used to \emph{prove} the properties of the programs. For example, we can prove, that for
arbitrary $n,\, m\in\mathbb{N}$ 

\[
\sembr{\llang{read (x); read (y); z := x + y; write (z)}}^\ph_\mathscr{S}\,\inbr{n,\,m}=n+m
\]

Indeed, we just need to repeat the construction of the derivation tree as we did in the evluation case, but this time instead of concrete numbers use
their abstract denotations $n$ and $m$; all steps could be performed as before until we arrive at the assignment rule. This time we would need to prove
an additional lemma

\[
\sembr{\llang{x + y}}^\ph_\mathscr{E}\,[\llang{x}\mapsto n,\,\llang{y}\mapsto m]=n+m
\]

which, of course, can be easily done by unfolding corresponding rule for $\sembr{\bullet}^\ph_\mathscr{E}$.

And, besides proving the properties of \emph{concrete programs}, big-step operational semantics can be used to prove the properties
of the semantics of the \emph{language} as whole. We consider some examples in the next section.

\subsection{Properties of the Semantics}

Now we formulate some simple properties of the semantics for straight-line programs; as the language is rather simple, these
properties and their proofs might look obvious. We nevertheless do this as a set of warming-up exersices to demonstrate
relevant techniques before dealing with more advanced languages with less trivial properties.

\subsubsection{Associativity of Composition}

First we consider rather an expected property of sequential composition to be \emph{associative}.

\begin{lemma}[Associativity of composition] For arbitrary $s_1,\,s_2,\,s_3$ and arbitrary $c_1,\,c_2$

\[
\trans{c_1}{\llang{$s_1$; ($s_2$; $\,s_3$)}}{c_2}\xLeftrightarrow{\phantom{XXX}}{}\trans{c_1}{\llang{($s_1$; $\,s_2$); $\,s_3$}}{c_2}
\]


In other words, the grouping of statements inside compositions is not essential, only their order.
\end{lemma}

\begin{proof}
Proving this claim amounts to
proving it in both directions; we only do it from left to right since the opposite can be done similarly. So, we assume

\[
\trans{c_1}{\llang{$s_1$; ($s_2$; $\,s_3$)}}{c_2}\eqno{(\star)}
\]

From this it is immedialety follows that

\[
\trule{\trans{c_1}{s_1}{c^\prime}\quad\trans{c^\prime}{\llang{$s_2$; $\,s_3$}}{c_2}}
      {\trans{c_1}{\llang{$s_1$; ($s_2$; $\,s_3$)}}{c_2}}
\]

because there is no way to complete the derivation tree for $(\star)$ other than by applying the rules of the semantics (this time, $\rulename{Seq}$).
Similarly, we can apply the same rule for the second premise, which gives us

\[
\trule{\trans{c_1}{s_1}{c^\prime}\qquad\trule{\trans{c^\prime}{s_2}{c^{\prime\prime}}\quad\trans{c^{\prime\prime}}{s_3}{c_2}}{\trans{c^\prime}{\llang{$s_2$; $\,s_3$}}{c_2}}}
      {\trans{c_1}{\llang{$s_1$; ($s_2$; $\,s_3$)}}{c_2}}
\]

Thus, we may conclude, that

\[
\begin{array}{c}
  \trans{c_1}{s_1}{c^\prime}\\
  \trans{c^\prime}{s_2}{c^{\prime\prime}}\\
  \trans{c^{\prime\prime}}{s_3}{c_2}
\end{array}
\]

for some configurations $c^\prime$ and $c^{\prime\prime}$. Now we turn our attention to the following evaluation relation:

\[
\trans{c_1}{\llang{($s_1$; $\,s_2$); $\,s_3$}}{\fbox{?}}
\]

We have to prove that $\fbox{?}=c_2$; again, applying rule $\rulename{Seq}$ twice we arrive at (a partial) derivation tree

\[
\trule{\trule{\trans{c_1}{s_1}{\fbox{???}}\quad\trans{\fbox{???}}{s_2}{\fbox{??}}}
             {\trans{c_1}{\llang{$s_1$; $\,s_2$}}{\fbox{??}}}\qquad\trans{\fbox{??}}{s_3}{\fbox{?}}}
      {\trans{c_1}{\llang{($s_1$; $\,s_2$); $\,s_3$}}{\fbox{?}}}
\]

By the determinism of the semantics we can conclude that $\fbox{???}=c^\prime$, from which (again, by determinism) immediately follows that
$\fbox{??}=c^{\prime\prime}$ and, finally, that $\fbox{?}=c_2$.
\end{proof}

Note, we did not use anything besides the rule $\rulename{Seq}$, thus
the associativity of composition does not depend on other rules and will hold as long as the rule $\rulename{Seq}$
is kept in its current form.

From what we've just proven it is immediately follows that for arbitrary $s_1,\,s_2,\,s_3$ 

\[
\sembr{\llang{$s_1$; ($s_2$; $\,s_3$)}}^\ph_\mathscr{S}=\sembr{\llang{($s_1$; $\,s_2$); $\,s_3$}}^\ph_\mathscr{S}
\]

In other words, regrouping the components of composition is an equivalent transformation.

\subsubsection{Finite Read and Write}

The next property we are going to establish is that every statement can read only a finite number of input
stream elements; this number depends only on the statement itself, and for all initial configurations with an input stream
shorter than that number the evaluation never comes to a final configuration. Formally, we prove the following lemma:

\begin{lemma}[Finite read] For any statement $s$ there is a natural number $n$ such that for every configuration $c=\inbr{\sigma,\,\inbr{i,\,o}}$

\begin{enumerate}
\item if $|i|<n$ then there is no configuration $c^\prime$ such that $\trans{c}{s}{c^\prime}$;
\item if $|i|\ge n$ and there is some configuration $c^\prime=\inbr{\sigma^\prime,\,\inbr{i^\prime,\,o^\prime}}$ such that $\trans{c}{s}{c^\prime}$, then
  $|i^\prime|=|i|-n$.
\end{enumerate}

\end{lemma}

\begin{proof}   
The proof goes by structural induction. For the base case we need to consider four simple statements and four corresponding semantics rules.
By inspecting the rules $\rulename{Skip}$, $\rulename{Assign}$, and $\rulename{Write}$ we can conclude that neither of them touches input stream. Thus,
if an evaluation according to these rules succesfully completes, then input streams of initial and final configurations are equal. This means that for these
three statements $n=0$.

On the contrary, the rule $\rulename{Read}$ takes one element from input stream and puts it into a state. In the final configuration input stream will be one
element shorter, and this configuration can not be constructed if the initial one had empty input stream. Thus, in this case $n=1$.

To complete the proof, we need to perform an induction step by inspecting the rule $\rulename{Seq}$. Let us have a statement $s_1\llang{;}s_2$; by
induction hypothesis we may conclude, that there are numbers $n_1$ and $n_2$ such the claim is true for $s_1$ and $s_2$, respectively. Let first
assume, that for some configuration $c=\inbr{\sigma,\,\inbr{i,\,o}}$ there is another one $c^\prime=\inbr{\sigma^\prime,\,\inbr{i^\prime,\,o^\prime}}$ such that

\[
\trans{c}{s_1\llang{;}s_2}{c^\prime}
\]

By unfolding the rule $\rulename{Seq}$ we have


\[
\trule{\trans{c}{s_1}{\inbr{\sigma^{\prime\prime},\,\inbr{i^{\prime\prime},\,o^{\prime\prime}}}}\quad\trans{\inbr{\sigma^{\prime\prime},\,\inbr{i^{\prime\prime},\,o^{\prime\prime}}}}{s_2}{c^\prime}}
      {\trans{c}{s_1\llang{;}s_2}{c^\prime}}
\]

From induction hypothesis for $s_1$ we know, that $|i^{\prime\prime}|=|i|-n_1$; from induction hypothesis for $s_2$ we know, that $|i^\prime|=|i^{\prime\prime}|-n_2$; thus, overall
$|i^\prime|=|i|-n_1-n_2$, or $|i^\prime|=|i|-(n_1+n_2)$ and $n=n_1+n_2$.

Let us now assume that $|i|<n_1+n_2$. If $|i|<n_1$, then, by the induction hypothesis for $s_1$, there is no configuration $c^{\prime\prime}$ such that

\[
\trans{\inbr{\sigma,\,\inbr{i,\,o}}}{s_1}{c^{\prime\prime}}
\]

If $n_1\le|i|<n_1+n_2$ and there is a configuration $c^{\prime\prime}=\inbr{\sigma^{\prime\prime},\,\inbr{i^{\prime\prime},\,o^{\prime\prime}}}$ such that

\[
\trans{\inbr{\sigma,\,\inbr{i,\,o}}}{s_1}{c^{\prime\prime}}
\]

then $|i^{\prime\prime}|<n_2$ by induction hypothesis for $s_1$; by induction hypothesis for $s_2$ there is no configuration $c^\prime$ such that

\[
\trans{c^{\prime\prime}}{s_2}{c^\prime}
\]

which completes the proof.
\end{proof}

A similar property can be established for output streams.

\begin{lemma}[Finite write] Let $s$ be a statement. Then there is a natural number $n$ such that for each
pairs of configurations $c=\inbr{\sigma,\,\inbr{i,\,o}}$ and $c^\prime=\inbr{\sigma^\prime,\,\inbr{i^\prime,\,o^\prime}}$ if

\[
\trans{c}{s}{c^\prime}
\]

then $|o^\prime|=|o|+n$.
\end{lemma}

\begin{proof}
  Like in the previous lemma, the principle of structural induction gives us the blueprint for the proof.
  In the base case, we consider four simple statements and corresponding semantics rules. For all cases, except for
  $\rulename{Write}$, the output stream is left untouched, thus $n=0$. For $\rulename{Write}$, if the statement
  managed to succeed, the output stream in the final configuration is one element longer, than in the initial
  one, thus $n=1$.

  In the induction step case, we have a statement $s_1\llang{;}s_2$ and we assume that lemma holds for $s_1$ and $s_2$; this
  gives us the numbers $n_1$ and $n_2$. Next we assume that

  \[
  \trans{c}{s_1\llang{;}s_2}{c^\prime}
  \]

  and unfold the rule $\rulename{Seq}$:

  \[
  \trule{\trans{c}{s_1}{\inbr{\sigma^{\prime\prime},\,\inbr{i^{\prime\prime},\,o^{\prime\prime}}}}\quad\trans{\inbr{\sigma^{\prime\prime},\,\inbr{i^{\prime\prime},\,o^{\prime\prime}}}}{s_2}{c^\prime}}
        {\trans{c}{s_1\llang{;}s_2}{c^\prime}}
  \]


  By induction hypothesis for $s_1$ we know that $|o^{\prime\prime}|=|o|+n_1$; by induction hypothesis for $s_2$~--- that $|o^\prime|=|o^{\prime\prime}|+n_2$. Thus, $|o^\prime|=|o|+(n_1+n_2)$, from
  which we conclude $n=n_1+n_2$.
\end{proof}

We can see the similarity between these two proofs; to tell the truth this is the case for all claims that can be proven by structural induction. Thus, almost every time
when we encounter such a claim we will skip the proof.

From these two lemmas we can derive the following corollaries:

\begin{enumerate}
\item For arbitrary $s\in\mathscr{S}$,$\,i,\,i^\prime\in\mathbb{Z}^*$ if both $\sembr{s}^\ph_\mathscr{S}\,i$ and $\sembr{s}^\ph_\mathscr{S}\,i^\prime$ defined, then
  \[
  |\sembr{s}^\ph_\mathscr{S}\,i|=|\sembr{s}^\ph_\mathscr{S}\,i^\prime|
  \]

  In other words, the length of the result depends only on the statement, not input data.

\item
  Let $\sembr{s}^\ph_\mathscr{S}\,i$ is defined for some $s\in\mathscr{S}$ and $i\in\mathbb{Z}^*$. Then for arbitrary $i^\prime\in\mathbb{Z}^*$

  \[
   \sembr{s}^\ph_\mathscr{S}\,ii^\prime=\sembr{s}^\ph_\mathscr{S}\,i
   \]

   In other words, if a program has returned some result for some input, it will also return the same result
   if we arbitrarily extend this input. The proof uses the determinism property of the semantics.
\end{enumerate}

\subsubsection{Variable Renaming}

The last example of a semantic property we are going to consider is \emph{equivalence up to variable renaming}.

By observing the semantics of expressions and statements we may notice that to some extent all variables
are indistinguishable: no rule requires any \emph{specific} variable to be used, any variable can be potentially used
anywhere. Thus, if we, for example, have an assignment

\begin{lstlisting}[mathescape=true]
   a := $E$
\end{lstlisting}

we can rename ``\lstinline|a|'' in, say, ``\lstinline|b|'', and nothing changes as long as we simultaneously
rename all following occurrencies of ``\lstinline|a|'' to ``\lstinline|b|'' as well. We have, however, to be
careful to avoid  \emph{coalescing} different variables into one; for example, if ``\lstinline|b|'' already
used in the same program, the result of renaming may or may not be correct depending on the properties
of this concrete program. Thus, we should only consider \emph{one-to-one} variable renamings.

More formally, we call a function

\[
\theta : \mathscr{X}\to\mathscr{X}
\]

a \emph{renaming} iff the following two conditions hold:

\begin{enumerate}
\item $\theta$ is total (defined for each $x\in\mathscr{X}$);
\item for each $y\in\mathscr{X}$ there is a unique $x\in\mathscr{X}$ such that $\theta\,(x)=y$.
\end{enumerate}

This is in fact a mathematical definition of a \emph{bijective} mapping from $\mathscr{X}$ to $\mathscr{X}$.
It is immediately follows from the definition that the inverse mapping $\theta^{-1}$ exists, which is
also a bijection. Moreover, both compositions $\theta\theta^{-1}$ and $\theta^{-1}\theta$ are identity
functions.

We now define what is a result of application of a renaming $\theta$ to an expression $e$ (notation: $e\,\theta$):

\[
\begin{array}{rclcl}
  x\,\theta&=&\theta\,(x)&,&x\in\mathscr{X}\\
  n\,\theta&=&n&,&n\in\mathbb{N}\\
  (l\oplus r)\,\theta&=&(l\,\theta)\oplus(r\,\theta)&
\end{array}
\]

In a nutshell, $e\,\theta$ is an expression in which all variables are substituted to their images according to $\theta$.
Similarly, we can extend the application of renaming to statements:

\[
\begin{array}{rcl}
  \llang{skip}\,\theta&=&\llang{skip}\\
  (x\llang{:=}e)\,\theta&=&(\theta\,(x))\llang{:=}(e\,\theta)\\
  (\llang{read ($x$)})\,\theta&=&\llang{read ($\theta\,(x)$)}\\
  (\llang{write ($e$)})\,\theta&=&\llang{write ($e\,\theta$)}\\
  (s_1\llang{;}s_2)\,\theta&=&(s_1\,\theta)\llang{;}(s_2\;\theta)
\end{array}
\]

\begin{lemma}
  Let $s$ be a statement and $\theta$ be a renaming. Then

  \[
  s\equiv s\,\theta
  \]
\end{lemma}
\begin{proof}
  First, we recollect that

  \[
  s\equiv s\,\theta
  \]

  means precisely

  \[
  \sembr{s}^\ph_\mathscr{S}=\sembr{s\,\theta}^\ph_\mathscr{S}
  \]

  Since $\sembr{\bullet}^\ph_\mathscr{S}$ is defined in terms of evaluation relation ``$\transrel$'' we need to prove
  a similar claim for ``$\transrel$''. This claim on the first glance may look like the follows: for all $c,\,c^\prime\in\mathscr{C}$

  \[
  \trans{c}{s}{c^\prime}\xLeftrightarrow{\phantom{XXX}}{}\trans{c}{s\,\theta}{c^\prime}
  \]

  Alas, this does not hold in general case: let us have a statement $\llang{write ($x$)}$ and let
  $\theta\,(x)=y$. Then for a configuration $c=\inbr{[x\mapsto 3],\,\inbr{i,\,o}}$ there is no $c^\prime$
  such that

  \[
  \trans{c}{\llang{write ($y$)}}{c^\prime}
  \]

  since $y$ is undefined in $[x\mapsto 3]$. The problem here is that renamed statements only behave similarly to the original ones
  in \emph{renamed} states.

  The fixed claim looks like the follows: let $c=\inbr{\sigma,\,w}$ and $c^\prime=\inbr{\sigma^\prime,\,w^\prime}$ then

  \[
  \trans{c}{s}{c^\prime}\xLeftrightarrow{\phantom{XXX}}{}\trans{\inbr{\sigma\circ\theta^{-1},\,w}}{s\,\theta}{\inbr{\sigma^\prime\circ\theta^{-1},\,w^\prime}}\eqno{(\clubsuit)}
  \]

  Informally speaking here we ``repair'' states for renamed statements by first applying the \emph{inverse} renaming $\theta^{-1}$ which exists by bijectivity of $\theta$. To
  prove this we need additional claim.

  \begin{claim}[$\spadesuit$]
    Let $e$ be an expression, $\sigma$ be a state, and $n$ be an integer number. Then

    \[
    \sembr{e}^\ph_\mathscr{E}\,\sigma=n \xLeftrightarrow{\phantom{XXX}}{}\sembr{e\,\theta}^\ph_\mathscr{E}\,(\sigma\circ\theta^{-1})=n
    \]
  \end{claim}
  \begin{proof}
    One may expect that the proof has to be performed in two directions. However, by the bijectivity of $\theta$

    \[
    \begin{array}{rcl}
      \theta&=&(\theta^{-1})^{-1}\\
      (e\,\theta)\,\theta^{-1}&=&e\\
      \sigma&=&(\sigma\circ\theta^{-1})\circ\theta
    \end{array}
    \]

    Thus, if we prove the claim from left to right, then (by arbitrariness of $e$, $\sigma$, and $\theta$) we can
    assume

    \[
    \begin{array}{rcl}
      e&=&e\,\theta\\
      \sigma&=&\sigma\circ\theta^{-1}
    \end{array}
    \]

    and the right-to-left direction will follow from left-to-right immediately.
    
    The proof proceeds by structural induction.

    The base case is a constant or a variable. Since the semantics of constants does not depend on a state the
    claim for constant case follows vacuously. If $e$ is a variable $x$, then:

    \[
    \begin{array}{rcl}
      \sembr{x\,\theta}^\ph_\mathscr{E}\,(\sigma\circ\theta^{-1})&=&\mbox{(by the definition of $\sembr{\bullet}^\ph_\mathscr{E}$)}\\
      (\sigma\circ\theta^{-1})\,(x\,\theta)&=&\mbox{(by the definition of renaming application)}\\
      (\sigma\circ\theta^{-1})\,(\theta\,(x))&=&\mbox{(by the definition of function composition)}\\
      ((\sigma\circ\theta^{-1})\circ\theta)\,(x)&=&\mbox{(by the associativity of function composition)}\\
      (\sigma\circ(\theta^{-1}\circ\theta))\,(x)&=&\mbox{(by the definition of function inversion)}\\
      \sigma\,(x)&=&\mbox{(by the condition of the claim)}\\
      n&&
    \end{array}
    \]

    The induction step assumes that the claim holds for some expressions $l$ and $r$; we need to prove that it also holds for
    $l\oplus r$:

    \[
    \begin{array}{rcl}
      \sembr{(l\oplus r)\,\theta}\,(\sigma\circ\theta^{-1})&=&\mbox{(by the definition of renaming application)}\\
      \sembr{(l\,\theta)\oplus(r\,\theta)}\,(\sigma\circ\theta^{-1})&=&\mbox{(by the definition of $\sembr{\bullet}^\ph_\mathscr{E}$)}\\
      \sembr{l\,\theta}\,(\sigma\circ\theta^{-1})\otimes\sembr{r\,\theta}\,(\sigma\circ\theta^{-1})&=&\mbox{(by inductive hypotheses)}\\
      \sembr{l}\,\sigma\otimes\sembr{r}\,\sigma&=&\mbox{(by the condition of the claim)}\\
      n&&      
    \end{array}
    \]

    This completes the proof.
  \end{proof}

  The proof of $(\clubsuit)$ goes by structural induction as well. Similarly to the claim $(\spadesuit)$ we only need to prove it in
  one direction (let it be left-to-right).

  In the base case we have to consider four types of simple statements:

  \begin{enumerate}
  \item As $\llang{skip}$ does not change a configuration the lemma holds vacuously.
  \item Let us have an assignment $x\llang{:=}e$. First, by the definition of renaming application

    \[
    (x\llang{:=}e)\,\theta=(\theta\,(x))\llang{:=}(e\,\theta)
    \]

    Then, by the definition of ``$\transrel$'':
    
    \[
    \trans{\inbr{\sigma\circ\theta^{-1},\,w}}{(\theta\,(x))\llang{:=}(e\,\theta)}{\inbr{(\sigma\circ\theta^{-1})[\theta\,(x)\gets\sembr{e\,\theta}^\ph_\mathscr{E}\,(\sigma\circ\theta^{-1})],\,w}}
    \]

    By $(\spadesuit)$ we know that

    \[
    \sembr{e\,\theta}^\ph_\mathscr{E}\,(\sigma\circ\theta^{-1})=\sembr{e}^\ph_\mathscr{E}\,\sigma
    \]

    By the definition of substitution in a state

    \[
    (\sigma\circ\theta^{-1})[\theta\,(x)\gets\sembr{e}^\ph_\mathscr{E}\,\sigma]\,y=\left\{\begin{array}{rcl}
                                                                                         \sembr{e}^\ph_\mathscr{E}\,\sigma&,&y=\theta\,(x)\\
                                                                                         (\sigma\circ\theta^{-1})\,y&,&y\ne\theta\,(x)
                                                                                       \end{array}\right.
    \]

    By the properties of functional inversion and composition and, again, using the definition of substitution in a state we have

    \[
    \left\{\begin{array}{rcl}
                                                                                         \sembr{e}^\ph_\mathscr{E}\,\sigma&,&y=\theta\,(x)\\
                                                                                         (\sigma\circ\theta^{-1})\,y&,&y\ne\theta\,(x)
                                                                                       \end{array}\right.=
   \left\{\begin{array}{rcl}
   \sembr{e}^\ph_\mathscr{E}\,\sigma&,&\theta^{-1}\,(y)=x\\
   (\sigma\,(\theta^{-1}\,(y))&,&\theta^{-1}\,(y)\ne x
    \end{array}\right.=(\sigma[x\gets\sembr{e}^\ph_\mathscr{E}])\,(\theta^{-1}\,(y))
    \]

    Thus, $\sigma^\prime=\sigma[x\gets\sembr{e}^\ph_\mathscr{E}]\circ\theta^{-1}$ which completes the proof for the assignment case.
    
  \item Two remaining cases can be proven similarly using the observation that worlds are invariant under renaming.
    
  \end{enumerate}
  
  Finally, to prove the induction step we assume that $(\clubsuit)$ holds for statements $s_1$ and $s_2$ and we need
  to prove

  \[
  \trans{\inbr{\sigma\circ\theta^{-1},\,w}}{s_1\llang{;}s_2}{\inbr{\sigma^\prime\circ\theta^{-1},\,w^\prime}}
  \]

  From the condition of the lemma we know

  \[
  \trule{\trans{\inbr{\sigma,\,w}}{s_1}{\inbr{\sigma^{\prime\prime},\,w^{\prime\prime}}}\quad\trans{\inbr{\sigma^{\prime\prime},\,w^{\prime\prime}}}{s_2}{\inbr{\sigma^\prime,\,w^\prime}}}
        {\trans{\inbr{\sigma,\,w}}{s_1\llang{;}s_2}{\inbr{\sigma^\prime,\,w^\prime}}}
  \]

  for some $\sigma^{\prime\prime}$ and $w^{\prime\prime}$. Applying the induction hypotheses to the premises and then applying rule $\rulename{Seq}$ we acquire the following
  derivation

  \[
  \trule{\trans{\inbr{\sigma\circ\theta^{-1},\,w}}{s_1}{\inbr{\sigma^{\prime\prime}\circ\theta^{-1},\,w^{\prime\prime}}}\quad\trans{\inbr{\sigma^{\prime\prime}\circ\theta^{-1},\,w^{\prime\prime}}}{s_2}{\inbr{\sigma^\prime\circ\theta^{-1},\,w^\prime}}}
        {\trans{\inbr{\sigma\circ\theta^{-1},\,w}}{s_1\llang{;}s_2}{\inbr{\sigma^\prime\circ\theta^{-1},\,w^\prime}}}
  \]

  which proves the induction step.

  Now, assume

  \[
  \trans{\inbr{\Lambda,\,\inbr{i,\,\epsilon}}}{s}{\inbr{\sigma,\,w}}
  \]

  By $(\clubsuit)$ we have

  \[
  \trans{\inbr{\Lambda\circ\theta^{-1},\,\inbr{i,\,\epsilon}}}{s\,\theta}{\inbr{\sigma\circ\theta^{-1},\,w}}
  \]

  But $\Lambda\circ\theta^{-1}=\Lambda$, which completes the proof since now we have 

  \[
  \sembr{s}^\ph_\mathscr{E}\,i=\sembr{s\,\theta}^\ph_\mathscr{E}\,i
  \]

  for arbitrary $i$ by the definition of $\sembr{\bullet}^\ph_\mathscr{E}$.
  
\end{proof}

\begin{comment}
First, we define the set of all \emph{free variables} $\fv{}$ in expression or statement:

\[
\begin{array}{rclcl}
  \fv{x} &=& \{x\}&,& x\in\mathscr{X}\\
  \fv{z} &=&\emptyset &,&z\in\mathbb{N}\\
  \fv{l\oplus r} &=& \fv{l}\cup\fv{r}&&
\end{array}
\]

\[
\begin{array}{rcl}
  \fv{\llang{skip}}&=&\emptyset\\
  \fv{x\,\llang{:=}\,e}&=&\{x\}\cup\fv{e}\\
  \fv{\llang{read ($x$)}}&=&\{x\}\\
  \fv{\llang{write ($e$)}}&=&\fv{e}\\
  \fv{s_1\llang{;}s_2}&=&\fv{s_1}\cup\fv{s_2}xs  
\end{array}
\]
\end{comment}
